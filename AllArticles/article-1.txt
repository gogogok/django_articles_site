Как написать парсер сайта на Python
Автор: Danylo Tiutiushkin
Дата создания: 06.06.2023
Ресурс: https://mate.academy/blog/ru/python-ru/python-web-parser/

В этой статье мы рассмотрим, как создать базовый парсер сайта на Python, используя библиотеки BeautifulSoup и requests. Он сможет спарсить информацию со страниц сайта и сохранять ее для последующего анализа.

Что такое веб-парсинг?
Парсинг — это процесс извлечения данных из веб-страниц. Эти данные могут включать любую информацию, доступную на веб-странице: текст, ссылки, изображения, метаданные и т.д. Веб-парсеры используются для различных задач, включая мониторинг цен, анализ социальных медиа, веб-майнинг, веб-аналитику и т.д.

Необходимые инструменты
Для начала, нам необходимо установить две библиотеки Python: requests и beautifulsoup4. Это можно сделать при помощи pip:


pip install requests beautifulsoup4
Requests — это библиотека Python, что позволяет нам выполнять HTTP-запросы, а BeautifulSoup — мощная библиотека для парсинга HTML и XML документов.

Начало работы
Для демонстрации мы напишем простой веб-парсер, который соберет заголовки статей с главной страницы блога на условном домене example.com. Первым шагом будет получение HTML-кода страницы. Мы воспользуемся для этого библиотекой requests:


import requests

url = 'https://example.com/blog/'
response = requests.get(url)
Если все прошло гладко, response.text теперь содержит HTML-код главной страницы блога.

Парсинг HTML
Теперь, когда у нас есть HTML-код страницы, мы можем воспользоваться BeautifulSoup для его парсинга:


from bs4 import BeautifulSoup

soup = BeautifulSoup(response.text, 'html.parser')
BeautifulSoup преобразует HTML-строку в объект, с которым легко работать, предоставляя различные методы для навигации и поиска в HTML-структуре.

Поиск данных
С помощью BeautifulSoup мы можем использовать CSS-селекторы для поиска элементов на странице. Например, давайте найдем все заголовки статей на странице. Просмотрев код страницы, мы видим, что заголовки находятся в тегах <h2>, которые имеют класс blog-title.


titles = soup.select('h2.blog-title')
select возвращает список всех найденных элементов. Если нам нужен только первый найденный элемент, мы можем использовать метод select_one.

Извлечение данных
Теперь, когда мы нашли наши заголовки, мы можем вытянуть из них текст:


for title in titles:
print(title.get_text())
Используя метод get_text(), мы можем получить весь текст, который находится внутри элемента, включая все его дочерние элементы.

Сохранение данных
Последний шаг — это сохранение собранных данных. Мы можем сохранить их в файл, базу данных или любое другое место в зависимости от наших потребностей. Для простоты давайте сохраним их в текстовый файл:


with open('titles.txt', 'w') as f:
for title in titles:
f.write(title.get_text() + '\n')
Теперь у нас есть простой парсер, который собирает заголовки с сайта и сохраняет их в текстовый файл.

Итоги
В этой статье мы рассмотрели основы написания веб-парсера на Python с использованием библиотек requests и BeautifulSoup. Это базовый пример, но принципы, которые мы здесь использовали, могут быть применены для написания намного более сложных веб-парсеров. Благодаря Python и его прекрасным библиотекам, парсинг становится простым и доступным инструментом для сбора данных из Интернета.

Если вы хотите расширить свои знания и навыки в написании парсеров на Python, вот несколько рекомендаций:

Изучить больше о CSS селекторах и их использовании в BeautifulSoup для поиска нужных элементов.
Ознакомиться с различными методами для навигации по DOM-структуре, такими как .parent, .children, .next_sibling и другие.
Рассмотреть использование других библиотек Python для веб-парсинга, таких как lxml, html5lib или PyQuery.
Исследовать возможности использования веб-парсеров для автоматического заполнения форм, работы с авторизацией на сайтах и обхода защиты от парсинга (например, CAPTCHA).
Кроме того, при написании веб-парсеров важно учитывать этические аспекты и соблюдать правила использования веб-сайтов. Проверяйте, разрешен ли парсинг и уважайте ограничения на частоту запросов.

С опытом и соблюдением лучших практик, написание парсеров на Python станет неотъемлемой частью вашего набора навыков, которая поможет вам собирать и анализировать данные из Интернета для различных целей.

Освоить профессию python разработчика вы можете на нашем курсе Python с трудоустройством.
